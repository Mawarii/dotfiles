## Rocket Chat image version
## ref: https://hub.docker.com/r/rocketchat/rocket.chat/tags
##
image:
  repository: registry.rocket.chat/rocketchat/rocket.chat
  pullPolicy: IfNotPresent
  tag: 6.5.3

imagePullSecrets: []

## Host for the application
## set it to a domain pointing to your loadbalancer
host: "rocketchat.cloudical.net"

replicaCount: 0
minAvailable: 0

smtp:
  enabled: false
  username:
  password:
  host:
  port: 587

# Extra env vars for Rocket.Chat:
extraEnv:
  # - name: MONGO_OPTIONS
  #   value: '{"ssl": "true"}'
  # - name: MONGO_OPLOG_URL
  #   value: mongodb://oploguser:password@rocket-1:27017/local&replicaSet=rs0

# Extra volumes for Rocket.Chat...
extraVolumes:
  # - name: etc-certs
  #   hostPath:
  #     path: /etc/ssl/certs
  #     type: Directory
  # - name: usr-certs
  #   hostPath:
  #     path: /usr/share/ca-certificates
  #     type: Directory

# ... and where they should be mounted inside the container
extraVolumeMounts:
  # - mountPath: /etc/ssl/certs
  #   name: etc-certs
  #   readOnly: true
  # - mountPath: /usr/share/ca-certificates
  #   name: usr-certs
  #   readOnly: true

# -- Containers, which are run before the app containers are started.
extraInitContainers: []
  # - name: init-myservice
  #   image: busybox
  #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']

## Specifies a Registration Token (obtainable at https://cloud.rocket.chat)
#registrationToken: ""

## Specifies an Enterprise License
# license: ""

## Pod anti-affinity can prevent the scheduler from placing RocketChat replicas on the same node.
## The default value "soft" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.
## The value "hard" means that the scheduler is *required* to not schedule two replica pods onto the same node.
## The value "" will disable pod anti-affinity so that no anti-affinity rules will be configured.
##
podAntiAffinity: "hard"

## If anti-affinity is enabled sets the topologyKey to use for anti-affinity.
## This can be changed to, for example, failure-domain.beta.kubernetes.io/zone
##
podAntiAffinityTopologyKey: kubernetes.io/hostname

## Assign custom affinity rules to the RocketChat instance
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
##
affinity: {}
# nodeAffinity:
#   requiredDuringSchedulingIgnoredDuringExecution:
#     nodeSelectorTerms:
#     - matchExpressions:
#       - key: kubernetes.io/e2e-az-name
#         operator: In
#         values:
#         - e2e-az1
#         - e2e-az2

## Use an existing secret file with the MongoDB Url and OplogUrl
existingMongodbSecret: ""

## MongoDB URL if using an externally provisioned MongoDB
externalMongodbUrl: mongodb://rocketchat:N7m3pflAoZd_p1tsjmtQmVHw8ewrUxxVOW9XhPF-fddGDqnvXoCWlnBkWxbo9TJtZ3h4dYdO82hWFRTMnHJTxI13-AjdQZFRNtQg8La2ZIzeV9BHj2Wa5FsdWqMui1b5@rocketchat-external-redis-headless:27017/rocketchat
externalMongodbOplogUrl: mongodb://root:3CWqDYGpA2bhGi4_SvwfsTGzAW523jScBT6L4E-NqSgh1TAaud_uOTFL0D8ZoJiY0Ve9mloM02pVHRUyNujRtrdazwJe8SOM4UvII7kAtvBBBUAQE240i5veRTHGv0QH@rocketchat-external-redis-headless:27017/local?replicaSet=rs0&authSource=admin

##
## MongoDB chart configuration
### ref https://github.com/helm/charts/tree/master/stable/mongodb#configuration
##
mongodb:
  ## Enable or disable MongoDB dependency completely.
  enabled: false

  initdbScriptsConfigMap: rocketchat-mongodb-fix-clustermonitor-role-configmap

  auth:
    rootPassword: "3CWqDYGpA2bhGi4_SvwfsTGzAW523jScBT6L4E-NqSgh1TAaud_uOTFL0D8ZoJiY0Ve9mloM02pVHRUyNujRtrdazwJe8SOM4UvII7kAtvBBBUAQE240i5veRTHGv0QH"
    username: "rocketchat"
    password: "N7m3pflAoZd_p1tsjmtQmVHw8ewrUxxVOW9XhPF-fddGDqnvXoCWlnBkWxbo9TJtZ3h4dYdO82hWFRTMnHJTxI13-AjdQZFRNtQg8La2ZIzeV9BHj2Wa5FsdWqMui1b5"
    database: "rocketchat"

  architecture: replicaset
  replicaCount: 1
  arbiter:
    enabled: true
    pdb:
      minAvailable: 0
  pdb:
    minAvailable: 0

    key: "z2itFNg/xXuQcvRTIyDkKW22dKq1xcsqun6DY4i6fLX0Iw/IZgkENiiP5Zi0mjNq21rgNG4MVW3riJe0AOSuuvgicxGFWTxcZB006PslTZxoDF6kyAp95+HTZzbtJtrDN/Rx76JMQs48Z+mFperY+xvwZHLmDtF3SdJT9cucrAbm+LQ2vbhfjowONh6upmYmm+bEtb1NdAqcDQCv9wwxzlduYWeCRKmyShIgAE2Y+50OObZnsyViDWP0hIn/ihaaEGd8u7gW9Mmp/E6FxI4DHetYBGhqBdKWN4Q2hkzOuYGGeAKl4rQ8Fkb55BNx2FYlxJJm/aKToamex8+Rn82A2ShA0K/18wOtejb/isXzGi5/Q2JdtrYPy8dbko7ReAvMC0UxjYEMZXGhqDSXxd5idEXoX8uN5h+8lfEamjv0hgobY/hLD+LAMg3knpYtTmY+Vju2k3rCm8/l7dynCbCPzO9j4w5nbhTPYM+jkyOXRPj+eM/aUBgRBVmBjg6NRkk5w9MPADy/f6BLgc6RP5UHka92rzObmunuhxNy7CKcDcXeQDT8CIkcl+drdCkqrGNP6c3jMV3ULWHyp/yEywjVWA4JavY3M6hGi7SFWxA/3vXCyvhlrSWS6BjO64LnRRf+rWfMe4Zny2dM6iduUT+ReJ/V5q+pjadO0FqUIcj3fS5l9Tj3y5jGWJ4rf5pnhB5dyQR2pVnnd11o9D4udncvrwvQ1ivmZpCgl4wqvq44WB0X8Op/MraEihLEJYqidU1ZSA2iuvi0xUwTfbEain60GWxWklhJsF0SPensLbuFT/ZBJvlXiEzxOhUajHwylkZImYPXP+jo1kUQQyRQxVO6YhwbZUE5uMNkR0O+2pQs2lbuZzPbXCj8QbCoaNwhkWkzCuqU64qhVV9nMtuzBd/ydk6lmUaQnoxb5YEcgTE8qqOjh5mrwlnjJ0wJhBlXRPQraFDRKoRYyfh8WN95v/9X3+d93yXuZEzehx4jtbznIkUjMwx8"
  persistence:
    enabled: true
    ## mongodb data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessMode: ReadWriteOnce
    size: 25Gi

  volumePermissions: { enabled: true }

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  enabled: false
  # existingClaim: existingClaimName
  ## rocketchat data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 8Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 768Mi
    cpu: 500m

securityContext:
  enabled: true
  runAsUser: 999
  fsGroup: 999

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true

  # Annotations to add to the ServiceAccount
  annotations: {}
  # eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/dummyRole

  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

## Configure the ingress object to hook into existing infastructure
### ref : http://kubernetes.io/docs/user-guide/ingress/
###
ingress:
  enabled: true
  pathType: Prefix
  ingressClassName: "nginx"
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 13m
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    kubernetes.io/tls-acme: "true"
  path: /
  tls:
    - secretName: tls-net-cloudical-rocketchat
      hosts:
        - rocketchat.cloudical.net

service:
  annotations: {}
  # service.beta.kubernetes.io/aws-load-balancer-internal: "0.0.0.0/0"

  labels: {}
  # key: value

  ## ServiceType
  ## ref: https://kubernetes.io/docs/user-guide/services/#publishing-services---service-types
  type: ClusterIP

  ## Optional static port assignment for service type NodePort.
  # nodePort: 30000

  port: 80

  ## Optional when LoadBalancer specified ServiceType.
  loadBalancerIP: ""

## Optional custom labels for the deployment resource.
deploymentLabels: {}

## Optional Pod Labels.
podLabels: {}

## Optional Pod Annotations.
podAnnotations:
  # prometheus.io/port: "9458"
  # prometheus.io/path: "/metrics"
  # prometheus.io/scrape: "true"
  backup.velero.io/backup-volumes: rocket-data

## Optional Prometheus scraping Settings
prometheusScraping:
  enabled: true
  port: 9100 # Avoid using 9458: conflicts with Moleculer Exporter

serviceMonitor:
  ## serviceMonitor.enabled Create ServiceMonitor resource(s) for scraping metrics using PrometheusOperator
  ## prometheusScraping.enabled should be also enabled
  ##
  enabled: false
  ## metrics.serviceMonitor.interval The interval at which metrics should be scraped
  ##
  interval: 30s
  ## metrics.serviceMonitor.port The port name at which container exposes Prometheus metrics
  ##
  port: metrics

## Liveness and readiness probe values
## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
##
livenessProbe:
  enabled: true
  path: /health
  initialDelaySeconds: 60
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 1

readinessProbe:
  enabled: true
  path: /health
  initialDelaySeconds: 10
  periodSeconds: 15
  timeoutSeconds: 5
  failureThreshold: 3
  successThreshold: 1

podDisruptionBudget:
  enabled: true

# # # # # # # # # # # # # # # # #
#   M I C R O S E R V I C E S   #
#  Only available to E.E users  #
# # # # # # # # # # # # # # # # #

## Deploy as microservices?
# Monolithic architecture, by default
microservices:
  enabled: false

  logLevel: warn

  heartbeatInterval: 10
  heartbeatTimeout: 30

  ## Parameters for each deployment:
  presence:
    replicas: 1
    image:
      repository: rocketchat/presence-service
      pullPolicy: IfNotPresent
    securityContext: {}
    resources: {}
  ddpStreamer:
    replicas: 1
    image:
      repository: rocketchat/ddp-streamer-service
      pullPolicy: IfNotPresent
    securityContext: {}
    resources: {}
  account:
    replicas: 1
    image:
      repository: rocketchat/account-service
      pullPolicy: IfNotPresent
    securityContext: {}
    resources: {}
  authorization:
    replicas: 1
    image:
      repository: rocketchat/authorization-service
      pullPolicy: IfNotPresent
    securityContext: {}
    resources: {}
  streamHub:
    replicas: 1
    image:
      repository: rocketchat/stream-hub-service
      pullPolicy: IfNotPresent
    securityContext: {}
    resources: {}
  nats:
    replicas: 1

  ## Parameters for each Kubernetes service
  # NOTE: reserved for future usage still
  presenceService:
  ddpStreamerService:
  natsService:
  streamHubService:
  accountService:
  authorizationService:

nats:
  nats:
    image: nats:2.4-alpine
